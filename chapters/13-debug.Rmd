# Отладка кода
## Анализ стека вызовов
Когда код реализован так, что внутри одной функции вызываются другие функция, а нередко еще и объявленная в отдельном файле, или даже каскад вложенных функций, бывает очень сложно разобраться, где же именно произошла ошибка.

В таких ситуациях в при поиске ошибок полезно использовать функцию `traceback()`, которая отслеживает иерархию вызовов и указывает, на какой строчке функции возникла ошибка.

Например, у нас есть две функции, `fun_h()` и `fun_z()`, в первой вызывается вторая, и во второй есть некорректная операция - сложение числа со строкой.

```{r 13-debug-1}
# первая функция, с вложенным вызовом
fun_h <- function(x, y) {
  x <- x + rnorm(1)
  fun_z(x, y)
}

# функция с ошибкой
fun_z <- function(x, y) {
  res <- x ^ 2 + abs(y) + 'z'
  res
}
```

Вызываем функцию `fun_h(x = 3, y = -5)` и смотрим результаn `traceback()` (приведена копия вывода из консоли):
```{r 13-debug-2, eval=FALSE, echo=FALSE}
fun_h(x = 3, y = -5)
traceback()
```

```{r 13-debug-3, eval=FALSE}
> fun_h(x = 3, y = -5)
Error in x^2 + abs(y) + "z" : non-numeric argument to binary operator
> traceback()
2: fun_z(x, y) at #3
1: fun_h(x = 3, y = -5)
```

Вывод функции `traceback()` - последовательность выполненных выражений, в порядке снизу вверх. Метка #3 означает, что ошибка произошла во время выполнения третьего выражения, так как сначала происходит выполнение выражения `x + rnorm(1)`, потом вызов функции `fun_z(x, y)` и потом выполнение ` x ^ 2 + abs(y) + 'z'`.

Вообще, `traceback()` очень удобен в ситуации, когда используются функции из внешних скриптов, подгружаемые через `source()` - в таких случаях указывется не только номер строки (ситуации, когда на одной строке несколько выражений достаточно редки), но и название файла, по маске `filename.r#linenumber`. Это позволяет легко искать и править ошибки в скриптах на сотни строк, что было бы очень сложно сделать иным способом.

При желании можно сразу задать в опциях сессии действия при возникновении ошибки, обычно это трейсбек или отладка (`recover()`). Указать трейсбек в действиях при ошибке можно таким выражением: `options(error = traceback)`, снять - указав `NULL`, `options(error = NULL)`.

```{r 13-debug-4, eval=FALSE, echo=FALSE}
options(error = traceback)
fun_h(x = 3, y = -5)
options(error = NULL)
```

```{r 13-debug-5, eval=FALSE}
> options(error = traceback)
> fun_h(x = 3, y = -5)
Error in x^2 + abs(y) + "z" : non-numeric argument to binary operator
2: fun_z(x, y) at #3
1: fun_h(x = 3, y = -5)
> options(error = NULL)
```


## Отладка с помощью debug()
Одно из самых неудобных в работе с функциями - сложно контролировать операции, которые происходят внутри функции и искать, когда что-то сломается. Наивное решение здесь - выносить тело функции в глобальное окружение, создавать одноименные аргументам объекты и поочередно запускать и тестировать операции.

Еще более простой путь - включить в функцию выражения вида `print(x)`, и таким образом контролировать процесс выполнения функции. Решение по простоте и изяществу не уступает топору, поэтому нередко в сообществе встречаются самоироничные высказывания типа `дебажу принтом`.

Намного удобнее, впрочем, воспользоваться встроенными функциями дебага - `debug() / undebug()` и `debugonce()`. В отличие от `debug()`, функция `debugonce()` вызывает интерфейс дебаггера однократно. При вызове `debugonce()` открывается интерфейс дебаггера - его можно опознать по `Browse` в командной строке.

Команды для работы в режиме отладки:

 - n / Enter: - выполнить следующее выражение (F10 в RStudio)
 
 - s: перейти область видимости вложенной функции (Shift+F4)
 
 - f: завершить функцию или цикл (Shift+F6)
 
 - с: продолжить выполнение (Shift+F5) 

 - Q:	выйти из режима отладки (Shift+F8)


Допустим, у нас есть простая функция, которая считает, сколько раз встречается та или иная цифра в векторе численных значений.
```{r 13-debug-6}
numbers_counter <- function(x) {
  x <- as.character(x)
  x <- gsub('[^0-9]', '', x)
  x <- strsplit(x, "")
  x <- unlist(x)
  digit.vector <- factor(x, levels = 0:9)
  res <- table(digit.vector)
  res
}
numbers_counter(sample(15))
```

Основной смысл отладки c помощью `debugonce()` - проверка, соответствует ли результат выполнения выражений в теле функции ожидаемому. Выражение `debugonce(numbers_counter)` указывает, что следующий запуск функции будет выполнен в режиме отладки (если указать `debug(numbers_counter)` - то при каждом вызове, пока не будет прекращена отладка с помощью `undebug(numbers_counter)`).

Вот так выглядит лог отладки в консоли. В консоли с `Browse[2]>` можно выполнять различные команды, в первую очередь, конечно, те, которые помогут получить информацию об объекте или рабочем окружении функции. Строчка `debug at` маркирует, до какого выражения дошла отладка, но само это выражение еще не выполнено.

Так, сначала мы смотрим, а какие же значения были переданы в аргумент `x` функции (первый `print(x)`). Далее последовательно выполняем выражения функции до выполнения `unlist(x)` - смотрим, что получилось в результате превращения переданного вектора значений в строки, удаления лишних знаков и разбора строкового вектора по символам с помощью `strsplit()` в вектор. После этого опять выполняем выражения, почти до самого конца, и перед последним выражением смотрим, что же вообще есть на этот момент в рабочем окружении функции (`ls()`). С выполнением последнего выражения функция завершает работу и мы ее получаем результат.

Так как использование дебаггера возможно только в интерактивном режиме, здесь и далее - копии вывода выполненных в консоли команд, а не реально сгенерированный во время рендера документа вывод
```{r 13-debug-7, eval=FALSE}
> debugonce(numbers_counter)
> numbers_counter(sample(15))
debugging in: numbers_counter(sample(15))
debug at #1: {
    x <- as.character(x)
    x <- gsub("[^0-9]", "", x)
    x <- strsplit(x, "")
    x <- unlist(x)
    digit.vector <- factor(x, levels = 0:9)
    res <- table(digit.vector)
    res
}
Browse[2]> print(x)
 [1] 12  6 14 10 13  9  2  4  5  1  3 11 15  7  8
Browse[2]> n
debug at #2: x <- as.character(x)
Browse[2]> n
debug at #3: x <- gsub("[^0-9]", "", x)
Browse[2]> n
debug at #4: x <- strsplit(x, "")
Browse[2]> n
debug at #5: x <- unlist(x)
Browse[2]> n
debug at #6: digit.vector <- factor(x, levels = 0:9)
Browse[2]> print(x)
 [1] "1" "2" "6" "1" "4" "1" "0" "1" "3" "9" "2" "4" "5" "1" "3" "1" "1" "1" "5" "7"
[21] "8"
Browse[2]> n
debug at #7: res <- table(digit.vector)
Browse[2]> n
debug at #8: res
Browse[2]> ls()
[1] "digit.vector" "res"          "x"           
Browse[2]> n
exiting from: numbers_counter(sample(15))
digit.vector
0 1 2 3 4 5 6 7 8 9 
1 8 2 2 2 2 1 1 1 1 
```

Помимо `debug()` есть альтернативная функция, `recover()`, которая в целом позволяет выбрать, какой из текущих вызовов, приведших к ошибке, следует проанализировать в дебаггере. Функцию `recover()` можно также указать в опциях действий при ошибке: `options(error = recover)`.

## breakpoints()
Когда известно, в каком месте может возникнуть ошибка (или же хочется проконтролировать какое-то определенное место в длинной функции, не проходя все выражения функции), то можно воспользоваться брекпоинтами. В IDE, в частности, в RStudio, брекпоинт ставится кликом мыши слева от номера строки выражения. Делать это нужно в файле, который потом будет вызван через `source()`.

В чистом R брекпоинты можно поставить с помощью функции `setBreakpoint()` (механизм брекпоинтов в IDE - также использует эту функцию). Для примера запишем функцию `numbers_counter()` в файл и выполним его:
```{r 13-debug-8}
# еще раз объявляем функцию и смотрим ее класс
numbers_counter <- function(x) {
  x <- as.character(x)
  x <- gsub('[^0-9]', '', x)
  x <- strsplit(x, "")
  x <- unlist(x)
  digit.vector <- factor(x, levels = 0:9)
  res <- table(digit.vector)
  res
}
class(numbers_counter)

# создаем файл и записываем в него функцию
dump('numbers_counter', file = 'numbers_counter.R')

# смотрим содежание файла
readLines('numbers_counter.R')
```


Поставим брекпоинт на восьмую строку, к этому моменту уже должны быть выполнены операции обработки вектора и создание объекта `digit.vector` класса фактор. Брейпоинт также можно поставить по маске, как и в трейсбеке - `filename.r#linenumber`. 

```{r 13-debug-9}
source('numbers_counter.R')
setBreakpoint(srcfile = 'numbers_counter.R#8')
```


Выполним функцию. При выполнении в интерактивном режиме открывается окно `Browse`, как и при использовании `debug()`, но дебаг начинается с восьмого выражения функции, предыдущие уже выполнены. 
```{r 13-debug-10, eval=FALSE}
# выполняем функцию
> numbers_counter(sample(15))
numbers_counter.R#8
Called from: numbers_counter(sample(15))
Browse[1]> n
debug: res <- table(digit.vector)
Browse[2]> ls()
[1] "digit.vector" "x"           
Browse[2]> f
digit.vector
0 1 2 3 4 5 6 7 8 9 
1 8 2 2 2 2 1 1 1 1 
```

При установке брейпоинта класс функции меняется (становится `functionWithTrace`), также вносисятся изменения в тело функции:
```{r 13-debug-11, eval=FALSE}
> class(numbers_counter)
[1] "functionWithTrace"
attr(,"package")
[1] "methods"
> body(numbers_counter)
{
    x <- as.character(x)
    x <- gsub("[^0-9]", "", x)
    x <- strsplit(x, "")
    x <- unlist(x)
    digit.vector <- factor(x, levels = 0:9)
    {
        .doTrace({
            cat(paste0("numbers_counter.R", "#", 8, "\n"))
            browser(skipCalls = 4L)
        })
        res <- table(digit.vector)
    }
    res
}
```


## Дебаг в неинтерактивном режиме
Основные функции дебага предназначены для интерактивной работы. Однако и при неинтерактивном выполнении скриптов можно делать пост-мортем анализ, чем же была вызвана ошибка. Для этого требуется, во-первых, в опцию действий при ошибке указать функцию дампа рабочего окружения срипта. Далее следует вызвать и проанализировать этот дамп с помощью помощью  `debugger()`.

```{r 13-debug-12, echo=FALSE}
opt <- "# задаем опции\noptions(error = quote(dump.frames(dumpto = 'last_dump', to.file = TRUE)))"
write(opt, 'script_with_errors.R')
dump(list = c('fun_h', 'fun_z'), 'script_with_errors.R', append = TRUE)
fcall <- "\n# вызываем функции\nfun_h(x = 3, y = -5)"
write(fcall, 'script_with_errors.R', append = TRUE)
```

Рассмотрим на уже использовавшихся ранее функций `fun_h()` и `fun_z()`. Допустим, у нас есть скрипт, в начале которого задано, что при ошибке дамп пишется в файл, потом объявляются две функции и происходит их вызов:
```{r 13-debug-13}
readLines('script_with_errors.R')
```

Выполняем скрипт `script_with_errors.R` - так как он написан с ошибкой, должен сгенерироваться файл дампа `last_dump.rda`. 

```{r 13-debug-14}
system('Rscript script_with_errors.R')
```

Проверим что файл дампа есть:
```{r 13-debug-15}
file.exists('last_dump.rda')

# импортируем дамп
load('last_dump.rda')
```

Запускаем дебаггер по дампу упавшего скрипта. Дебаггер, также, каки функция `recover()` возвращает стек вызовов по порядку, и предлагает выбрать, какое окружение запустить.При выборе 6, загрузки окружения функции `fun_z()`, открывается окно дебаггера:
```{r 13-debug-16, eval=FALSE}
> debugger(last_dump)
Message:  Error in x^2 + abs(y) + "z" : non-numeric argument to binary operator
Available environments had calls:
1: source("script_with_errors.R")
2: withVisible(eval(ei, envir))
3: eval(ei, envir)
4: eval(ei, envir)
5: script_with_errors.R#15: fun_h(x = 3, y = -5)
6: script_with_errors.R#6: fun_z(x, y)

Enter an environment number, or 0 to exit  
Selection: 6
Browsing in the environment with call:
   script_with_errors.R#6: fun_z(x, y)
Called from: debugger.look(ind)
Browse[1]> ls()
[1] "x" "y"
Browse[1]> Q
```

## Логирование процесса
При работе больших проектов (или просто регулярно выполняемых скриптов) будет правильным и полезным логировать как минимум наиболее важные этапы. Например, при задачах ETL хорошо бы логировать время начала скрипта, исходные параметры источника данных (дата, источник, и т.д.), какими версиями пакетов производилась обработка.

Простое и достаточно изящное решение здесь - воспользоваться пакетом `futile.logger`, который позволяет формировать сообщения с определеным набором парамеров и выводить в консоль, и/или записывать в файл лога. Еще одна приятная возможность `futile.logger` - создавать несколько параллельных логгеров, с разными настройками.

Например, функция `flog.info()` указывает тип сообщения - информационный, в выводе также есть время вызова и собственно текст сообщения.
```{r 13-debug-17}
library(futile.logger)
flog.info('просто вывод в консоль')
```

При желании можно изменить формат сообщения - для этого есть набор параметров:

 - ~l: уровень лога
 - ~t: дата и время вызова
 - ~n: пространство имен, в котором сделан вызов (актуально для системы логирования в пользовательских пакетах или же параллельно существующих логгерах)
 - ~f: функция, в теле которой есть вывод лога (shell для скрипта)
 - ~m: сообщение
 
```{r 13-debug-18}
# задаем формат сообщения
log_format <- layout.format('~t [~l]: ~m')
flog.layout(log_format)

# простой вывод в консоль
flog.info('просто вывод в консоль')
```

При желании можно даже сохранить формат вывода:
```{r 13-debug-19}
m <- matrix(rnorm(12), nrow = 3)
flog.info("Matrix:", m, capture = TRUE)
```

`futile.logger` предполагает иерархию типов сообщений, по степени информативности / критичности:  TRACE < DEBUG < INFO < WARN < ERROR < FATAL. Например, если есть необходимость подавить все сообщения, которые менее критичны, чем ошибки (TRACE - WARN), то можно задать порог отсечения, с помощью функции `flog.threshold()`:
```{r 13-debug-20}
# устанавливаем порог
flog.threshold(ERROR)

# все типы ниже порога подавляются
flog.info('info')
flog.trace('trace')

# тип выше порога выводится в консоль
flog.fatal('fatal')

# возвращаем логирование всех типов
flog.threshold(TRACE)
```


Логи также можно писать в файл. Для вывода в файл надо указать, что запись будет вестись в файл, а также указать формат записи - дописывание файла, или перезапись. Для примера будем писать лог во временный файл, в реальной пратике, конечно же, необходимо создавать файл на диске. Для одновременного вывода в консоль и записи в файл можно воспрользоваться функцией `appender.tee()`. 

Вот так выглядит минимальный логгер, когда во временный файл пишется стартовая информация о происходящем, потом выполняется функция с `flog.info()` внутри, и в конце в лог дописывается информация о сессии из `sessionInfo()`.
```{r 13-debug-21}
# создаем файл и указываем заголовок лога
log_file <- tempfile()
flog.appender(appender.file(log_file))
flog.info('Тестируем запись в файл')

# выполняем выражение и результат пишем в лог
m <- matrix(rnorm(12), nrow = 3)
flog.info("Matrix:", m, capture = TRUE)

# дописываем в файл лога информацию о системе
flog.info("SESSION INFO:", sessionInfo(), capture = TRUE)
```

Результат:
```{r 13-debug-22}
readLines(log_file)
```

```{r 13-debug-23, echo=FALSE}
unlink('numbers_counter.R')
unlink('last_dump.rda')
unlink('script_with_errors.R')
```



## Best practices
General principles

Code for readability
"Always code as if the guy who ends up maintaining your code will be a violent psychopath who knows where you live."
Attributed to many famous programmers.

The quote says it all. “It works” is good enough for school projects or outsourcing companies, who need to finish a project as cheap and dirty as it’s possible and then they’ll never see it again, or at least will be paid for maintenance. More complicated projects have a way longer lifetime and are being changed time to time. When you’re about to push something - take a look at your code and think: “Will I be able to easily understand what’s going on here when in a year we suddenly realize, we have a critical bug? Will my colleagues be able to easily understand what’s going on here if tomorrow I’ll be hit by bus?”. If one of the answers is “I’m not sure”, looks like there’s some work to be done.

Saving 10 minutes on improving code readability often leads to wasting 10 hours of your colleagues, when they’re trying to understand your module.

Document your code
"Talk is cheap. Show me the code."
Linus Torvalds.

Readable code is cool, it gives you an idea of what’s going on. But it doesn’t really explain, why, what for and what role it plays in the overall process. There’s a always a chance that a completely correct and neat piece of code is doing something terribly wrong and people let it go through, because they don’t understand what this code is about. So every function that is more complicated than a simple arithmetical operation should be documented properly. If you have a feeling: “If people have questions - I’ll give them a few hours long talk about how things work!”, looks like there’s some work to be done.

Care about all the codebase
“Always check a module in cleaner than when you checked it out.”
Robert C. Martin (Uncle Bob).

No one is perfect, we all make mistakes and trade-offs even if we really try to write readable and well documented code. It’s especially likely to leave some leftovers and questionable parts if you were working on some module for a long time. So if you’re given a new module that you’re not familiar with too much to add some functionality or to fix something and it’s not really ASAP - it’s really nice to familiarize yourself with its codebase and try to improve something, either in code or documentation. Sometimes a single glance of fresh eyes can make a great difference.

Think first
“All the problems of the world could be settled easily if men were only willing to think.”
Thomas J. Watson.

Uncle Bob’s “Clean Architecture” book starts with an example of a company that wanted to iterate fast. They released their first version extremely fast with a small number of programmers. But with every next version maintenance complexity was increasing exponentially, they needed to hire more and more developers, testers, teamleads, etc, and development cost was growing even faster, since developers are not cheap.
He says it could be avoided, if they were not making so many trade-offs and were not rushing with the very first decision they had in mind, trying to foresee the consequences of implementing it.

Be consistent
“Without requirements or design, programming is the art of adding bugs to an empty text file.”
Louis Srygley.

To have an evolving product we need to have a maintainable codebase. We have plenty of different fields where different technologies should be used. When we make decisions about technologies, design, architecture, and coding style, we need to keep in mind both our actual situation and our business requirements. Technologies choices should be based not on individual preferences or experiences but on our actual needs, on what will serve our tasks best in our situation.

If code formatting helps us to read code, it should be consistent across all the projects.
If typing is used in some project, it should be used everywhere in the project.

Test your code
“All code is guilty, until proven innocent.”
Anonymous.

It’s even more important in our case, since we don’t use strongly typed programming language. Something that is not tested properly is as good as something that is not done at all. Proper well-thought unit testing is even more important than code itself, because it will be your only guard that won’t let you or your colleague to break expected behaviour because of a typo, logical mistake or simple misunderstanding.

If something can’t be unit-tested, it should be tested functionally, if it can’t be tested functionally, it must be tested manually few times and it must be clearly documented, so other people working with this code are aware that this part is extremely sensible.

Keeping the importance of proper testing in mind…

Treat Test code as Production code
Everything that was said above is applicable to your tests. They should be clean, they should be documented, it would be nice to have them short. And if you need to create or expand a testing framework, this framework should be tested itself.

Practical proposals
"Debugging is twice as hard as writing the code in the first place. Therefore, if you write the code as cleverly as possible, you are, by definition, not smart enough to debug it."
Brian W. Kernighan.

Code formatters should be used and they should be consistent across the projects. There’s a proposal to use Black for Python.

Linters should be used in CI/CD pipelines to ensure that code complexity is not too high and there are no other flows. pylint3 was used in Edge pipelines. There were 2 main requirements: pylint score was expected to be higher than 9.0 and there was expected to be no functions with McCabe complexity score higher than 7.

If typing is used (which is generally a good idea), it’s beneficial to use analyzers like mypy to ensure, that there are no contradictions in types. Variable names are sometimes misleading, proper typing helps a lot to avoid confusion.

Try to stick to official standards of your programming language where possible. If you use Java, your variables should be named using camelCase, if you use Python, snake_case is your choice. Following PEP8 for Python looks like a good idea, especially if pylint and black are used. We know there are exclusions like Python logging library that inherited camelCase from log4j. Shame on them. Consistency is the key.

There is no universal standard. Different languages have different standards. Know your tool.

Document your tests. When code is not clear, people check tests, when tests are not clear as well, people start distracting other people with questions and overall efficiency goes down dramatically. Gherkin syntax (or its subset GIVEN WHEN THEN) works pretty well.

Share your knowledge. E.g. groupby in Python works differently to how it works in other languages or even in PySpark. If you know it, people who work with you on the same projects should know it as well.

Name variables properly, using English. A very long variable name is better than an unclear variable name.

Write short understandable functions and methods. Most functions can be less than 25 lines of effective code long. If your function is longer, highly likely there’s a possibility to refactor it by separating some code to external or
 
internal functions.

Remember, “later” in “I’ll refactor it later” normally means “never”.

Do not repeat yourself, try to avoid code duplication.

And Keep It Simple, Stupid.
